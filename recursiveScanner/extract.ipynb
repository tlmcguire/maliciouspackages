{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tarfile\n",
    "import ast\n",
    "import json\n",
    "import pandas as pd\n",
    "import math\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "from scipy.stats import entropy\n",
    "import logging\n",
    "import sys\n",
    "import xml.etree.ElementTree as ET\n",
    "import re\n",
    "from lxml import etree\n",
    "import joblib\n",
    "\n",
    "logstd = logging.StreamHandler(sys.stdout)\n",
    "\n",
    "logging.basicConfig(\n",
    "    format=\"%(asctime)s %(levelname)s %(name)s:%(lineno)d - %(message)s\",\n",
    "    datefmt=\"%Y-%m-%d %H:%M:%S %Z\",\n",
    "    level=logging.INFO,\n",
    "    handlers=[logstd]\n",
    ")\n",
    "\n",
    "log = logging.getLogger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_setup_json_files(directory):\n",
    "    setup_json_files = []\n",
    "    for root, dirs, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            if file == 'setup.json':\n",
    "                setup_json_files.append(os.path.join(root, file))\n",
    "    return setup_json_files\n",
    "\n",
    "def is_valid_json_file(file_path):\n",
    "    try:\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            json.load(file)\n",
    "        return True\n",
    "    except (ValueError, json.JSONDecodeError):\n",
    "        return False\n",
    "\n",
    "def count_valid_json_files(directory):\n",
    "    count = 0\n",
    "    for root, _, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            if file == \"setup.json\" and is_valid_json_file(os.path.join(root, file)):\n",
    "                count += 1\n",
    "    return count\n",
    "\n",
    "def count_package_files(directory):\n",
    "    count = 0\n",
    "    for root, dirs, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            if file.endswith(\".tar.gz\") or file.endswith(\".tar.bz2\") or file.endswith(\".tar.xz\"):\n",
    "                count += 1\n",
    "    return count\n",
    "\n",
    "def is_valid_json_file(file_path):\n",
    "    try:\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            json.load(file)\n",
    "        return True\n",
    "    except (ValueError, json.JSONDecodeError):\n",
    "        return False\n",
    "\n",
    "def count_valid_json_files(directory):\n",
    "    count = 0\n",
    "    for root, _, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            if file == \"setup.json\" and is_valid_json_file(os.path.join(root, file)):\n",
    "                count += 1\n",
    "    return count\n",
    "\n",
    "def find_setup_json_files(directory):\n",
    "    setup_json_files = []\n",
    "    for root, dirs, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            if file == 'setup.json':\n",
    "                setup_json_files.append(os.path.join(root, file))\n",
    "    return setup_json_files\n",
    "\n",
    "def find_python_files(directory):\n",
    "    python_files = []\n",
    "    for entry in os.scandir(directory):\n",
    "        if entry.is_file() and entry.name.endswith('.py') and not entry.name.startswith('.'):\n",
    "            python_files.append(entry.path)\n",
    "        elif entry.is_dir():\n",
    "            python_files.extend(find_python_files(entry.path))\n",
    "    return python_files\n",
    "\n",
    "def read_json_files(directory):\n",
    "    json_data_list = []\n",
    "\n",
    "    for root, dirs, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            if file == 'setup.json':\n",
    "                file_path = os.path.join(root, file)\n",
    "                with open(file_path, 'r') as f:\n",
    "                    json_data = json.load(f)\n",
    "                    print(f\"Read {file_path}: {json_data}\")  # Debug statement\n",
    "                    json_data_list.append(json_data)\n",
    "\n",
    "    df = pd.DataFrame(json_data_list)\n",
    "    return df\n",
    "\n",
    "\n",
    "scan_directory = \"./packages/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert setup.py files to JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(level=logging.DEBUG)\n",
    "log = logging.getLogger(__name__)\n",
    "\n",
    "def parse_setup_py(setup_py_path):\n",
    "    setup_args = {}\n",
    "    try:\n",
    "        with open(setup_py_path, 'r', encoding='utf-8') as f:\n",
    "            content = f.read()\n",
    "\n",
    "        # Remove BOM if present\n",
    "        if content.startswith('\\ufeff'):\n",
    "            content = content[1:]\n",
    "\n",
    "        # Parse the content with AST\n",
    "        tree = ast.parse(content, filename=setup_py_path)\n",
    "\n",
    "        for node in tree.body:\n",
    "            if (isinstance(node, ast.Expr) and isinstance(node.value, ast.Call) and\n",
    "                    isinstance(node.value.func, ast.Name) and node.value.func.id == 'setup'):\n",
    "                for kwarg in node.value.keywords:\n",
    "                    try:\n",
    "                        value = ast.literal_eval(kwarg.value)\n",
    "                    except (ValueError, SyntaxError):\n",
    "                        # Fallback to using the repr of the value if literal_eval fails\n",
    "                        value = ast.dump(kwarg.value)\n",
    "                    setup_args[kwarg.arg] = value\n",
    "\n",
    "    except SyntaxError as e:\n",
    "        log.error(f\"SyntaxError in {setup_py_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "    return setup_args\n",
    "\n",
    "def convert_setup_to_json(dataset_dir):\n",
    "    setup_py_files = []\n",
    "    for root, _, files in os.walk(dataset_dir):\n",
    "        for file in files:\n",
    "            if file == 'setup.py':\n",
    "                setup_py_files.append(os.path.join(root, file))\n",
    "\n",
    "    for setup_py in setup_py_files:\n",
    "        setup_args = parse_setup_py(setup_py)\n",
    "        if setup_args is None:\n",
    "            continue  # Skip this setup.py due to SyntaxError\n",
    "\n",
    "        json_path = os.path.join(os.path.dirname(setup_py), 'setup.json')\n",
    "        with open(json_path, 'w', encoding='utf-8') as json_file:\n",
    "            json.dump(setup_args, json_file, indent=2)\n",
    "        log.debug(f'Converted {setup_py} to {json_path}')\n",
    "\n",
    "convert_setup_to_json(scan_directory)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Count zipped packages to determine useable amount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of packages in ./packages/: 1\n"
     ]
    }
   ],
   "source": [
    "package_count = count_package_files(scan_directory)\n",
    "\n",
    "print(f\"Number of packages in {scan_directory}: {package_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Count JSON files to determin useable amount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of valid setup.json files in ./packages/: 1\n"
     ]
    }
   ],
   "source": [
    "josn_count = count_valid_json_files(scan_directory)\n",
    "\n",
    "print(f\"Number of valid setup.json files in {scan_directory}: {josn_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate Shannon Entropy and append to JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found setup.json files:\n",
      "./packages/ospyata/ospyata-3.1.4/ospyata-3.1.4/setup.json\n",
      "Updated ./packages/ospyata/ospyata-3.1.4/ospyata-3.1.4/setup.json with average entropy: 4.646404428510623\n",
      "Shannon entropy of ospyata-3.1.4: 4.646404428510623\n"
     ]
    }
   ],
   "source": [
    "def shannon_entropy(directory):\n",
    "    package_entropies = {}\n",
    "    setup_json_files = find_setup_json_files(directory)\n",
    "    \n",
    "    for setup_file_path in setup_json_files:\n",
    "        package_path = os.path.dirname(setup_file_path)\n",
    "        package_name = os.path.basename(package_path)\n",
    "        \n",
    "        package_entropy = 0\n",
    "        total_files = 0\n",
    "        \n",
    "        python_files = find_python_files(package_path)\n",
    "        for file_path in python_files:\n",
    "            try:\n",
    "                with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:\n",
    "                    text = f.read()\n",
    "                    freqs = np.array(list(Counter(text).values()))\n",
    "                    probs = freqs / len(text)\n",
    "                    entropy_value = entropy(probs, base=2)\n",
    "                    package_entropy += entropy_value\n",
    "                    total_files += 1\n",
    "            except Exception as e:\n",
    "                print(f\"Error reading {file_path}: {e}\")\n",
    "        \n",
    "        if total_files > 0:\n",
    "            average_entropy = package_entropy / total_files\n",
    "            package_entropies[package_name] = average_entropy\n",
    "\n",
    "            try:\n",
    "                with open(setup_file_path, 'r+', encoding='utf-8', errors='ignore') as setup_file:\n",
    "                    try:\n",
    "                        setup_data = json.load(setup_file)\n",
    "                        setup_data[\"average_entropy\"] = average_entropy\n",
    "                        setup_file.seek(0)\n",
    "                        json.dump(setup_data, setup_file, indent=4)\n",
    "                        setup_file.truncate()\n",
    "                        print(f\"Updated {setup_file_path} with average entropy: {average_entropy}\")\n",
    "                    except json.JSONDecodeError as json_err:\n",
    "                        print(f\"JSON decode error in {setup_file_path}: {json_err}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error updating {setup_file_path}: {e}\")\n",
    "\n",
    "    return package_entropies\n",
    "\n",
    "setup_json_files = find_setup_json_files(scan_directory)\n",
    "\n",
    "if setup_json_files:\n",
    "    print(\"Found setup.json files:\")\n",
    "    for file in setup_json_files:\n",
    "        print(file)\n",
    "else:\n",
    "    print(\"No setup.json files found in the specified directory.\")\n",
    "\n",
    "package_entropies = shannon_entropy(scan_directory)\n",
    "for package, entropy in package_entropies.items():\n",
    "    print(f\"Shannon entropy of {package}: {entropy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construct AST and store in XML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XML representation saved for ./packages/ospyata/ospyata-3.1.4/ospyata-3.1.4/setup.py\n",
      "XML representation saved for ./packages/ospyata/ospyata-3.1.4/ospyata-3.1.4/src/ospyata/__init__.py\n",
      "XML representation saved for ./packages/ospyata/ospyata-3.1.4/ospyata-3.1.4/src/ospyata/__version__.py\n",
      "XML representation saved for ./packages/ospyata/ospyata-3.1.4/ospyata-3.1.4/src/ospyata/osmata.py\n"
     ]
    }
   ],
   "source": [
    "def construct_ast(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:\n",
    "        content = f.read()\n",
    "        try:\n",
    "            tree = ast.parse(content)\n",
    "            return tree\n",
    "        except SyntaxError as e:\n",
    "            print(f\"SyntaxError in {file_path}: {e}\")\n",
    "            return None\n",
    "\n",
    "def _convert(node, parent):\n",
    "    if isinstance(node, ast.AST):\n",
    "        node_name = node.__class__.__name__\n",
    "        element = ET.SubElement(parent, node_name)\n",
    "        for field, value in ast.iter_fields(node):\n",
    "            field_elem = ET.SubElement(element, field)\n",
    "            _convert(value, field_elem)\n",
    "    elif isinstance(node, list):\n",
    "        for item in node:\n",
    "            item_elem = ET.SubElement(parent, 'item')\n",
    "            _convert(item, item_elem)\n",
    "    else:\n",
    "        parent.text = str(node)\n",
    "\n",
    "def ast_to_xml(node):\n",
    "    root = ET.Element(node.__class__.__name__)\n",
    "    _convert(node, root)\n",
    "    return root\n",
    "\n",
    "def find_python_files(directory):\n",
    "    python_files = []\n",
    "    for root, _, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            if file.endswith('.py'):\n",
    "                python_files.append(os.path.join(root, file))\n",
    "    return python_files\n",
    "\n",
    "def save_xml(xml, file_path):\n",
    "    xml_str = ET.tostring(xml, encoding='unicode', method='xml')\n",
    "    xml_file_path = os.path.splitext(file_path)[0] + '.xml'\n",
    "    with open(xml_file_path, 'w', encoding='utf-8', errors='replace') as f:\n",
    "        f.write(xml_str)\n",
    "\n",
    "python_files = find_python_files(scan_directory)\n",
    "\n",
    "for file in python_files:\n",
    "    tree = construct_ast(file)\n",
    "    if tree is not None:\n",
    "        xml = ast_to_xml(tree)\n",
    "        save_xml(xml, file)\n",
    "        print(f\"XML representation saved for {file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Count number of .py files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scanning dataset directory: ./packages/\n",
      "Scanning package directory: ./packages/ospyata\n",
      "Updated ./packages/ospyata/ospyata-3.1.4/ospyata-3.1.4/setup.json with python_file_count: 4\n",
      "Package 'ospyata' has 4 Python files.\n"
     ]
    }
   ],
   "source": [
    "def count_python_files(directory):\n",
    "    python_file_count = 0\n",
    "    for entry in os.scandir(directory):\n",
    "        if entry.is_file() and entry.name.endswith('.py'):\n",
    "            python_file_count += 1\n",
    "        elif entry.is_dir():\n",
    "            python_file_count += count_python_files(entry.path)\n",
    "    return python_file_count\n",
    "\n",
    "def count_python_files_in_packages(directory):\n",
    "    package_counts = {}\n",
    "    \n",
    "    print(f\"Scanning dataset directory: {directory}\")\n",
    "    for entry in os.scandir(directory):\n",
    "        if entry.is_dir():\n",
    "            package_path = entry.path\n",
    "            print(f\"Scanning package directory: {package_path}\")\n",
    "            python_files_count = count_python_files(package_path)\n",
    "            package_name = entry.name\n",
    "            package_counts[package_name] = python_files_count\n",
    "            \n",
    "            setup_json_files = find_setup_json_files(package_path)\n",
    "            if setup_json_files:\n",
    "                for setup_json_path in setup_json_files:\n",
    "                    try:\n",
    "                        with open(setup_json_path, 'r') as file:\n",
    "                            data = json.load(file)\n",
    "                        \n",
    "                        data['python_file_count'] = python_files_count\n",
    "\n",
    "                        with open(setup_json_path, 'w') as file:\n",
    "                            json.dump(data, file, indent=4)\n",
    "\n",
    "                        print(f\"Updated {setup_json_path} with python_file_count: {python_files_count}\")\n",
    "                    except Exception as e:\n",
    "                        print(f\"Error updating {setup_json_path}: {e}\")\n",
    "            else:\n",
    "                print(f\"No setup.json found in {package_path}\")\n",
    "        else:\n",
    "            print(f\"Skipping non-directory entry: {entry.name}\")\n",
    "    \n",
    "    return package_counts\n",
    "\n",
    "package_python_file_counts = count_python_files_in_packages(scan_directory)\n",
    "\n",
    "for package, count in package_python_file_counts.items():\n",
    "    print(f\"Package '{package}' has {count} Python files.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the size of each package in bytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original setup.json data for ospyata-3.1.4: {'name': 'ospyata', 'license': 'MIT License', 'version': '3.1.4', 'description': 'Python library for the open source bookmark app Osmata.', 'long_description': \"Name(id='long_description', ctx=Load())\", 'long_description_content_type': 'text/markdown', 'url': 'https://github.com/aerocyber/ospyata', 'author': 'aerocyber', 'classifiers': ['Development Status :: 5 - Production/Stable', 'Intended Audience :: Developers', 'License :: OSI Approved :: MIT License', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.11', 'Programming Language :: Python :: 3 :: Only'], 'keywords': 'osmata, development, osmata-bindings, osmata-python-bindings, bookmarks, ospyata', 'package_dir': {'': 'src'}, 'packages': \"Call(func=Name(id='find_packages', ctx=Load()), args=[], keywords=[keyword(arg='where', value=Constant(value='src'))])\", 'python_requires': '>=3.09, <4', 'install_requires': [], 'project_urls': {'Bug Reports': 'https://github.com/aerocyber/ospyata/issues', 'Source': 'https://github.com/aerocyber/ospyata/'}, 'average_entropy': 4.646404428510623, 'python_file_count': 4}\n",
      "Updated setup.json data for ospyata-3.1.4: {'name': 'ospyata', 'license': 'MIT License', 'version': '3.1.4', 'description': 'Python library for the open source bookmark app Osmata.', 'long_description': \"Name(id='long_description', ctx=Load())\", 'long_description_content_type': 'text/markdown', 'url': 'https://github.com/aerocyber/ospyata', 'author': 'aerocyber', 'classifiers': ['Development Status :: 5 - Production/Stable', 'Intended Audience :: Developers', 'License :: OSI Approved :: MIT License', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.11', 'Programming Language :: Python :: 3 :: Only'], 'keywords': 'osmata, development, osmata-bindings, osmata-python-bindings, bookmarks, ospyata', 'package_dir': {'': 'src'}, 'packages': \"Call(func=Name(id='find_packages', ctx=Load()), args=[], keywords=[keyword(arg='where', value=Constant(value='src'))])\", 'python_requires': '>=3.09, <4', 'install_requires': [], 'project_urls': {'Bug Reports': 'https://github.com/aerocyber/ospyata/issues', 'Source': 'https://github.com/aerocyber/ospyata/'}, 'average_entropy': 4.646404428510623, 'python_file_count': 4, 'package_size': 50184}\n",
      "Successfully updated ./packages/ospyata/ospyata-3.1.4/ospyata-3.1.4/setup.json with package size: 50184\n",
      "Package 'ospyata-3.1.4' size: 50184 bytes\n"
     ]
    }
   ],
   "source": [
    "def calculate_package_sizes(directory):\n",
    "    package_sizes = {}\n",
    "\n",
    "    # Find all setup.json files in the directory\n",
    "    setup_json_files = find_setup_json_files(directory)\n",
    "\n",
    "    for setup_json_path in setup_json_files:\n",
    "        package_dir = os.path.dirname(setup_json_path)\n",
    "        package_name = os.path.basename(package_dir)\n",
    "\n",
    "        # Filter out tarfiles (.tar.gz, .tar.bz2, .tar.xz)\n",
    "        filtered_files = []\n",
    "        for root, dirs, files in os.walk(package_dir):\n",
    "            filtered_files += [os.path.join(root, filename) for filename in files \n",
    "                               if not (filename.endswith('.tar.gz') or filename.endswith('.tar.bz2') or filename.endswith('.tar.xz'))]\n",
    "\n",
    "        # Calculate size of remaining files\n",
    "        package_size = sum(os.path.getsize(filename) for filename in filtered_files)\n",
    "        package_sizes[package_name] = package_size\n",
    "\n",
    "        try:\n",
    "            # Read the existing setup.json file\n",
    "            with open(setup_json_path, 'r') as file:\n",
    "                data = json.load(file)\n",
    "            print(f\"Original setup.json data for {package_name}: {data}\")\n",
    "\n",
    "            # Append the package size to the setup.json data\n",
    "            data['package_size'] = package_size\n",
    "            print(f\"Updated setup.json data for {package_name}: {data}\")\n",
    "\n",
    "            # Write the updated data back to setup.json\n",
    "            with open(setup_json_path, 'w') as f:\n",
    "                json.dump(data, f, indent=4)\n",
    "            print(f\"Successfully updated {setup_json_path} with package size: {package_size}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error updating {setup_json_path}: {e}\")\n",
    "\n",
    "    return package_sizes\n",
    "\n",
    "# Calculate and print out the package sizes\n",
    "package_sizes = calculate_package_sizes(scan_directory)\n",
    "for package_name, size_in_bytes in package_sizes.items():\n",
    "    print(f\"Package '{package_name}' size: {size_in_bytes} bytes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove unwanted keys from setup.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def remove__key(file_path, key):\n",
    "#     try:\n",
    "#         with open(file_path, 'r') as file:\n",
    "#             data = json.load(file)\n",
    "        \n",
    "#         if key in data:\n",
    "#             del data[key]\n",
    "            \n",
    "#             with open(file_path, 'w') as file:\n",
    "#                 json.dump(data, file, indent=4)\n",
    "                \n",
    "#             print(f\"Removed {key} from {file_path}\")\n",
    "#         else:\n",
    "#             print(f\" {key} not found in {file_path}\")\n",
    "#     except Exception as e:\n",
    "#         print(f\"Error processing {file_path}: {e}\")\n",
    "\n",
    "# # Find all setup.json files in the directory\n",
    "# setup_json_files = find_setup_json_files(scan_directory)\n",
    "\n",
    "# # Remove the 'package_size_bytes' key from each setup.json file\n",
    "# for file_path in setup_json_files:\n",
    "#     remove__key(file_path, 'contains_require_child_process')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepend the directory name to setup.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prepended directory name 'ospyata' to ./packages/ospyata/ospyata-3.1.4/ospyata-3.1.4/setup.json\n"
     ]
    }
   ],
   "source": [
    "def prepend_directory_name_to_setup_json(directory):\n",
    "    for root, dirs, files in os.walk(directory):\n",
    "        if 'setup.json' in files:\n",
    "            setup_json_path = os.path.join(root, 'setup.json')\n",
    "            \n",
    "            # Extract the relative path and split to find the correct directory name\n",
    "            relative_path = os.path.relpath(root, directory)\n",
    "            directory_name = relative_path.split(os.sep)[0]\n",
    "            \n",
    "            # Read the existing content of the setup.json file\n",
    "            with open(setup_json_path, 'r') as file:\n",
    "                content = file.read()\n",
    "                data = json.loads(content)\n",
    "            \n",
    "            # Prepend the directory name\n",
    "            data = {\"directory_name\": directory_name, **data}\n",
    "            \n",
    "            # Write the updated content back to the setup.json file\n",
    "            with open(setup_json_path, 'w') as file:\n",
    "                json.dump(data, file, indent=4)\n",
    "            \n",
    "            print(f\"Prepended directory name '{directory_name}' to {setup_json_path}\")\n",
    "\n",
    "prepend_directory_name_to_setup_json(scan_directory)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parse .xml files for features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XML files found in ./packages/ospyata: ['./packages/ospyata/ospyata-3.1.4/ospyata-3.1.4/setup.xml', './packages/ospyata/ospyata-3.1.4/ospyata-3.1.4/src/ospyata/osmata.xml', './packages/ospyata/ospyata-3.1.4/ospyata-3.1.4/src/ospyata/__version__.xml', './packages/ospyata/ospyata-3.1.4/ospyata-3.1.4/src/ospyata/__init__.xml']\n",
      "Updated ./packages/ospyata/ospyata-3.1.4/ospyata-3.1.4/setup.json with extracted features\n",
      "Successful XML file parsing count: 4\n",
      "Unsuccessful XML file parsing count: 0\n"
     ]
    }
   ],
   "source": [
    "def extract_features_from_xml(directory):\n",
    "    setup_json_files = find_setup_json_files(directory)\n",
    "    successful_parsing_count = 0\n",
    "    unsuccessful_parsing_count = 0\n",
    "\n",
    "    for package in os.listdir(directory):\n",
    "        package_path = os.path.join(directory, package)\n",
    "        if not os.path.isdir(package_path):\n",
    "            continue\n",
    "\n",
    "        xml_files = []\n",
    "\n",
    "        for root, dirs, files in os.walk(package_path):\n",
    "            for file in files:\n",
    "                if file.endswith(\".xml\"):\n",
    "                    xml_file_path = os.path.join(root, file)\n",
    "                    xml_files.append(xml_file_path)\n",
    "\n",
    "        if xml_files:\n",
    "            print(f\"XML files found in {package_path}: {xml_files}\")\n",
    "        else:\n",
    "            print(f\"No XML files found in {package_path}\")\n",
    "\n",
    "        # Features to extract\n",
    "        contains_ip = 0\n",
    "        contains_domain = 0\n",
    "        contains_bytestrings = 0\n",
    "        contains_base64 = 0\n",
    "        contains_eval = 0\n",
    "        contains_import_subprocess = 0\n",
    "        contains_import_os = 0\n",
    "        contains_import_network_modules = 0\n",
    "        contains_os_environ_access = 0\n",
    "\n",
    "        # Patterns\n",
    "        ip_address_pattern = re.compile(r'\\b(?:[0-9]{1,3}\\.){3}[0-9]{1,3}\\b')\n",
    "        domain_pattern = re.compile(r'\\b(?:[a-zA-Z0-9-]+\\.)+[a-zA-Z]{2,}\\b')\n",
    "        bytestring_pattern = re.compile(r\"b'[^']*'\")\n",
    "        base64_pattern = re.compile(r'(?:(?:[A-Za-z0-9+/]{4})*(?:[A-Za-z0-9+/]{2}==|[A-Za-z0-9+/]{3}=)?)')\n",
    "\n",
    "        for xml_file in xml_files:\n",
    "            try:\n",
    "                parser = etree.XMLParser(recover=True)  # Ignore errors and continue parsing\n",
    "                tree = etree.parse(xml_file, parser=parser)\n",
    "                xml_root = tree.getroot()\n",
    "\n",
    "                if xml_root is None:\n",
    "                    print(f\"Error: Root element is None for file {xml_file}\")\n",
    "                    unsuccessful_parsing_count += 1\n",
    "                    continue\n",
    "\n",
    "                successful_parsing_count += 1\n",
    "\n",
    "                for element in xml_root.iter():\n",
    "                    if element.text:\n",
    "                        if not contains_ip:\n",
    "                            ips = ip_address_pattern.findall(element.text)\n",
    "                            if ips:\n",
    "                                contains_ip = 1\n",
    "\n",
    "                        if not contains_domain:\n",
    "                            domains = domain_pattern.findall(element.text)\n",
    "                            if domains:\n",
    "                                contains_domain = 1\n",
    "\n",
    "                        if not contains_bytestrings:\n",
    "                            bytestrings = bytestring_pattern.findall(element.text)\n",
    "                            if bytestrings:\n",
    "                                contains_bytestrings = 1\n",
    "\n",
    "                        if not contains_base64:\n",
    "                            base64s = base64_pattern.findall(element.text)\n",
    "                            if base64s:\n",
    "                                contains_base64 = 1\n",
    "\n",
    "                        if contains_ip and contains_domain and contains_bytestrings and contains_base64:\n",
    "                            break\n",
    "\n",
    "                    if element.tag == 'Call' and element.find('func') is not None and element.find('func').text == 'eval':\n",
    "                        contains_eval = 1\n",
    "\n",
    "                    if element.tag in ['Import', 'ImportFrom']:\n",
    "                        for child in element:\n",
    "                            if child.tag == 'names':\n",
    "                                for item in child:\n",
    "                                    if item.tag == 'item':\n",
    "                                        for alias in item:\n",
    "                                            if alias.tag == 'alias' and alias.find('name') is not None:\n",
    "                                                module_name = alias.find('name').text\n",
    "                                                if module_name == 'os':\n",
    "                                                    contains_import_os = 1\n",
    "                                                elif module_name == 'subprocess':\n",
    "                                                    contains_import_subprocess = 1\n",
    "                                                elif module_name.startswith('os'):\n",
    "                                                    contains_import_os = 1\n",
    "                                                elif module_name in ['socket', 'requests', 'http', 'urllib']:\n",
    "                                                    contains_import_network_modules = 1\n",
    "\n",
    "                    if element.tag == 'Attribute' and element.find('attr') is not None and 'environ' in element.find('attr').text:\n",
    "                        parent = element.find('value')\n",
    "                        if parent is not None and parent.tag == 'Attribute' and parent.find('value') is not None:\n",
    "                            grandparent = parent.find('value')\n",
    "                            if grandparent is not None and grandparent.tag == 'Name' and grandparent.text == 'os':\n",
    "                                print(f\"Detected os.environ access in: {etree.tostring(element, pretty_print=True)}\")\n",
    "                                contains_os_environ_access = 1\n",
    "                                break\n",
    "\n",
    "            except etree.XMLSyntaxError as e:\n",
    "                print(f\"Error parsing {xml_file}: {e}\")\n",
    "                unsuccessful_parsing_count += 1\n",
    "\n",
    "        # Find the corresponding setup.json file for this package\n",
    "        setup_json_file = None\n",
    "        for file_path in setup_json_files:\n",
    "            if file_path.startswith(package_path):\n",
    "                setup_json_file = file_path\n",
    "                break\n",
    "\n",
    "        if setup_json_file:\n",
    "            try:\n",
    "                with open(setup_json_file, 'r') as f:\n",
    "                    setup_data = json.load(f)\n",
    "\n",
    "                setup_data['contains_ip'] = contains_ip\n",
    "                setup_data['contains_domain'] = contains_domain\n",
    "                setup_data['contains_bytestrings'] = contains_bytestrings\n",
    "                setup_data['contains_base64'] = contains_base64\n",
    "                setup_data['contains_eval'] = contains_eval\n",
    "                setup_data['contains_import_subprocess'] = contains_import_subprocess\n",
    "                setup_data['contains_import_os'] = contains_import_os\n",
    "                setup_data['contains_import_network_modules'] = contains_import_network_modules\n",
    "                setup_data['contains_os_environ_access'] = contains_os_environ_access\n",
    "\n",
    "                with open(setup_json_file, 'w') as f:\n",
    "                    json.dump(setup_data, f, indent=4)\n",
    "                print(f\"Updated {setup_json_file} with extracted features\")\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error updating {setup_json_file}: {e}\")\n",
    "\n",
    "    print(f\"Successful XML file parsing count: {successful_parsing_count}\")\n",
    "    print(f\"Unsuccessful XML file parsing count: {unsuccessful_parsing_count}\")\n",
    "\n",
    "# Example call to the function\n",
    "extract_features_from_xml(scan_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cosntruct dependency graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO - Add code to construct dependency graphs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert to dataframe with option to save as CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read ./packages/ospyata/ospyata-3.1.4/ospyata-3.1.4/setup.json: {'directory_name': 'ospyata', 'name': 'ospyata', 'license': 'MIT License', 'version': '3.1.4', 'description': 'Python library for the open source bookmark app Osmata.', 'long_description': \"Name(id='long_description', ctx=Load())\", 'long_description_content_type': 'text/markdown', 'url': 'https://github.com/aerocyber/ospyata', 'author': 'aerocyber', 'classifiers': ['Development Status :: 5 - Production/Stable', 'Intended Audience :: Developers', 'License :: OSI Approved :: MIT License', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.11', 'Programming Language :: Python :: 3 :: Only'], 'keywords': 'osmata, development, osmata-bindings, osmata-python-bindings, bookmarks, ospyata', 'package_dir': {'': 'src'}, 'packages': \"Call(func=Name(id='find_packages', ctx=Load()), args=[], keywords=[keyword(arg='where', value=Constant(value='src'))])\", 'python_requires': '>=3.09, <4', 'install_requires': [], 'project_urls': {'Bug Reports': 'https://github.com/aerocyber/ospyata/issues', 'Source': 'https://github.com/aerocyber/ospyata/'}, 'average_entropy': 4.646404428510623, 'python_file_count': 4, 'package_size': 50184, 'contains_ip': 0, 'contains_domain': 1, 'contains_bytestrings': 0, 'contains_base64': 1, 'contains_eval': 0, 'contains_import_subprocess': 0, 'contains_import_os': 1, 'contains_import_network_modules': 0, 'contains_os_environ_access': 0}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>packages</th>\n",
       "      <th>version</th>\n",
       "      <th>average_entropy</th>\n",
       "      <th>python_file_count</th>\n",
       "      <th>package_size</th>\n",
       "      <th>contains_ip</th>\n",
       "      <th>contains_domain</th>\n",
       "      <th>contains_bytestrings</th>\n",
       "      <th>contains_base64</th>\n",
       "      <th>contains_import_subprocess</th>\n",
       "      <th>contains_import_os</th>\n",
       "      <th>contains_import_network_modules</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4.646404</td>\n",
       "      <td>4</td>\n",
       "      <td>50184</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   name  packages  version  average_entropy  python_file_count  package_size  \\\n",
       "0     1         1        1         4.646404                  4         50184   \n",
       "\n",
       "   contains_ip  contains_domain  contains_bytestrings  contains_base64  \\\n",
       "0            0                1                     0                1   \n",
       "\n",
       "   contains_import_subprocess  contains_import_os  \\\n",
       "0                           0                   1   \n",
       "\n",
       "   contains_import_network_modules  \n",
       "0                                0  "
      ]
     },
     "execution_count": 318,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Call the function and get the DataFrame\n",
    "df = read_json_files(scan_directory)\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "# columns_to_drop = ['package_size']\n",
    "# df = df.drop(columns=columns_to_drop)\n",
    "\n",
    "#save to CSV\n",
    "# df.to_csv('extracted.csv', index=False)\n",
    "\n",
    "# # #load df from CSV\n",
    "# df = pd.read_csv('extracted.csv')\n",
    "# df = df.reset_index(drop=True)\n",
    "\n",
    "columns_to_keep = ['name', 'packages', 'version', 'average_entropy', 'python_file_count', 'package_size', 'contains_ip', 'contains_domain', 'contains_bytestrings', 'contains_base64', 'contains_import_subprocess', 'contains_import_os', 'contains_import_network_modules']\n",
    "\n",
    "# Assign 0 to missing values and 1 to non-missing values\n",
    "columns_to_process = ['name', 'packages', 'version']\n",
    "\n",
    "# Assign 0 for missing values and 1 for non-missing values\n",
    "for col in columns_to_process:\n",
    "    df[col] = df[col].notnull().astype(int)\n",
    "\n",
    "# Filter out columns\n",
    "df = df.loc[:, columns_to_keep]\n",
    "\n",
    "# Display contents\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name: 0.00% empty rows\n",
      "packages: 0.00% empty rows\n",
      "version: 0.00% empty rows\n",
      "average_entropy: 0.00% empty rows\n",
      "python_file_count: 0.00% empty rows\n",
      "package_size: 0.00% empty rows\n",
      "contains_ip: 0.00% empty rows\n",
      "contains_domain: 0.00% empty rows\n",
      "contains_bytestrings: 0.00% empty rows\n",
      "contains_base64: 0.00% empty rows\n",
      "contains_import_subprocess: 0.00% empty rows\n",
      "contains_import_os: 0.00% empty rows\n",
      "contains_import_network_modules: 0.00% empty rows\n"
     ]
    }
   ],
   "source": [
    "# Display the percentage of empty rows in each column\n",
    "empty_rows = df.isnull().sum() * 100 / len(df)\n",
    "\n",
    "for column, percentage in empty_rows.items():\n",
    "    print(f\"{column}: {percentage:.2f}% empty rows\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>packages</th>\n",
       "      <th>version</th>\n",
       "      <th>average_entropy</th>\n",
       "      <th>python_file_count</th>\n",
       "      <th>package_size</th>\n",
       "      <th>contains_ip</th>\n",
       "      <th>contains_domain</th>\n",
       "      <th>contains_bytestrings</th>\n",
       "      <th>contains_base64</th>\n",
       "      <th>contains_import_subprocess</th>\n",
       "      <th>contains_import_os</th>\n",
       "      <th>contains_import_network_modules</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4.646404</td>\n",
       "      <td>4</td>\n",
       "      <td>50184</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   name  packages  version  average_entropy  python_file_count  package_size  \\\n",
       "0     1         1        1         4.646404                  4         50184   \n",
       "\n",
       "   contains_ip  contains_domain  contains_bytestrings  contains_base64  \\\n",
       "0            0                1                     0                1   \n",
       "\n",
       "   contains_import_subprocess  contains_import_os  \\\n",
       "0                           0                   1   \n",
       "\n",
       "   contains_import_network_modules  \n",
       "0                                0  "
      ]
     },
     "execution_count": 320,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove missing values in specified columns\n",
    "df = df.dropna(subset=['average_entropy', 'python_file_count', 'package_size', 'contains_ip', 'contains_domain', 'contains_bytestrings', 'contains_base64', 'contains_import_subprocess', 'contains_import_os', 'contains_import_network_modules'])\n",
    "df.head()\n",
    "\n",
    "# Display size of the dataframe\n",
    "# df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All features: 'name', 'packages', 'version', 'average_entropy', 'python_file_count', 'package_size', 'contains_ip', 'contains_domain', 'contains_bytestrings', 'contains_base64', 'contains_import_subprocess', 'contains_import_os', 'contains_import_network_modules'\n",
    "\n",
    "# Specify the columns to exclude\n",
    "# columns_to_exclude =  []\n",
    "\n",
    "# Read the CSV file excluding specified columns\n",
    "# df = pd.read_csv('extracted.csv', usecols=lambda x: x not in columns_to_exclude)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0])"
      ]
     },
     "execution_count": 322,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pyscan = joblib.load('pyscan.pkl')\n",
    "pyscan.predict(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
